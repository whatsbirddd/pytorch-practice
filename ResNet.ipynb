{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28ddfcd-729a-4a7e-9f55-49221d3e2c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import transforms, datasets\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149d021d-6c8c-40db-b3b8-46aa2b96ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps:0' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f00eb8f-3e51-4137-bf27-97558cfb7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weak augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Pad(4),\n",
    "    transforms.RandomCrop(32, fill=128),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41fb662f-e76f-47ab-90fe-be5edf5b69b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load the data and transform the dataset\n",
    "train_dataset =  datasets.CIFAR10(root='./data', train=True, download=True, transform = transform)\n",
    "validation_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform = transform)\n",
    "\n",
    "# Create train and validation batch for training\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b74dad30-9b14-4a32-99f3-5478f1c2aad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
       "          ...,\n",
       "          [-2.1179, -2.1179, -1.6042,  ..., -0.9363, -0.9877, -0.4054],\n",
       "          [-2.1179, -2.1179, -1.6213,  ..., -0.9877, -0.8849, -0.3883],\n",
       "          [-2.1179, -2.1179, -1.6555,  ..., -0.7822, -0.2684,  0.1083]],\n",
       " \n",
       "         [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
       "          ...,\n",
       "          [-2.0357, -2.0357, -0.3025,  ..., -0.4776, -0.3025,  0.6254],\n",
       "          [-2.0357, -2.0357, -0.3375,  ..., -0.4426, -0.2850,  0.5728],\n",
       "          [-2.0357, -2.0357, -0.3901,  ..., -0.4076, -0.0924,  0.9405]],\n",
       " \n",
       "         [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
       "          ...,\n",
       "          [-1.8044, -1.8044,  0.6531,  ..., -0.0790,  0.1825,  1.5420],\n",
       "          [-1.8044, -1.8044,  0.6182,  ...,  0.0431,  0.2871,  1.4548],\n",
       "          [-1.8044, -1.8044,  0.5659,  ...,  0.2871,  0.5659,  1.7337]]]),\n",
       " 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "58afdb18-864c-4304-840b-d7ad328259c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1 #(Q)너는 왜 1이야? (A)BottleNeck을 쓰는 이유를 생각해보면 됨!\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        \"\"\"\n",
    "        in_plane : in_channel 개수\n",
    "        planes : out_channel 개수\n",
    "        \"\"\"\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        # 논문 3.3에서 Residual Network부분 설명\n",
    "        # shortcut connection을 위해서 input과 output dimension이 동일해야함.\n",
    "        # dimentsion이 증가했을 때 (planes = 64에서 planes= 128로 증가할 때), zero padding을 해주거나 projection shortcut을 해줌.\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b5301f12-2578-4c8e-aca1-92283b91197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4 #(Q)너는 왜 4이야? (A)256 사이즈 그대로 보면 연산량이 너무 크니까 원하는만큼 채널을 줄여서 보자!\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        # (1*1) conv 채널 축소 : padding, stride 노상관\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False) \n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False) \n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes*self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes*self.expansion) #(256)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4d635362-ad4b-48ce-a202-f9a2611a7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        # 처음에 들어오는 이미지의 채널은 3\n",
    "        # conv1 (7*7, 64, stride=2) or (3*3, 64, stride=2) * N\n",
    "        # stride = 2로 downsampling\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, \n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        # layer2-4는 downsampling을 위해 stride = 2\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes) \n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        \"\"\"\n",
    "        block : block의 종류\n",
    "        planes : out_channel 수\n",
    "        num_blocks : block의 개수\n",
    "        \"\"\"\n",
    "        # (Q)첫 레이어만 stride받은 대로 하고 나머지 레이어의 stride는 1로 고정? \n",
    "        # (A)논문에 보면 stride = 2를 써서 downsampling해주는 부분이 있음.\n",
    "        strides = [stride] + [1]*(num_blocks-1) \n",
    "        layers = []\n",
    "        # (Q)왜 stride를 써서 했지? num_block을 쓰는 게 아니라..\n",
    "        # (A)stride가 블록 내에서 첫번째 레이어만 stide=2로 다운샘플링해주고 나머지는 stride=1을 사용\n",
    "        for stride in strides:\n",
    "            print(\"in_planes: \", self.in_planes, \"planes: \", planes)\n",
    "            layers.append(block(self.in_planes, planes, stride)) \n",
    "            # expansion이란? bottleneck의 차원축소때문에 사용하는 것\n",
    "            self.in_planes = planes * block.expansion #planes에 맞춰서 in_planes를 바꿔주기\n",
    "        return nn.Sequential(*layers) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1) #각 채널을 펼쳐서 linear에 넣어주기\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "fe844073-89bf-4e0c-9915-d9799571fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet34(num_classes):\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3], num_classes)\n",
    "\n",
    "\n",
    "def ResNet50(num_classes):\n",
    "    return ResNet(Bottleneck, [3, 4, 6, 3], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e8f1be0e-537d-4083-8af1-cdc470f22e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_planes:  64 planes:  64\n",
      "in_planes:  256 planes:  64\n",
      "in_planes:  256 planes:  64\n",
      "in_planes:  256 planes:  128\n",
      "in_planes:  512 planes:  128\n",
      "in_planes:  512 planes:  128\n",
      "in_planes:  512 planes:  128\n",
      "in_planes:  512 planes:  256\n",
      "in_planes:  1024 planes:  256\n",
      "in_planes:  1024 planes:  256\n",
      "in_planes:  1024 planes:  256\n",
      "in_planes:  1024 planes:  256\n",
      "in_planes:  1024 planes:  256\n",
      "in_planes:  1024 planes:  512\n",
      "in_planes:  2048 planes:  512\n",
      "in_planes:  2048 planes:  512\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9ef0749f-f0f6-4c4e-9c46-8aae5133ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "x = next(iter(train_loader))[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fc2009bb-4412-446c-9ed9-8b8785c86702",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0f25ca68-3bb6-4c69-bc56-7372f2790247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 10])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
